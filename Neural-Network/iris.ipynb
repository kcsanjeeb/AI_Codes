{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Flower Classification Neural Network with PyTorch\n",
    "A lightweight 3-layer neural network implemented in PyTorch for classifying Iris flower species (setosa, versicolor, virginica) based on four morphological features (sepal length/width, petal length/width). The model demonstrates:\n",
    "* **Architecture:** Input layer (4 nodes) → Hidden Layer 1 (8 nodes, ReLU) → Hidden Layer 2 (9 nodes, ReLU) → Output Layer (3 nodes)\n",
    "* **Training:** Uses Adam optimizer (lr=0.01) with CrossEntropyLoss over 100 epochs\n",
    "* **Performance:** Achieves ~95%+ accuracy with proper initialization (random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in features: sepal length, sepal width, petal length, petal width\n",
    "* out features: Iris Setosa, Iris Versicolour, or Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/damiannolan/iris-neural-network/14a9df14a57ab9d350b7bc92b2903fa1f25c4f1c/img/iris_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Input Layer (4 features of flowers) --> HL1 (number of neurons) --> HL2(n) --> Ouput(3 Classes of Iris Flower)\n",
    "    # fc -- fully connected 1 , fully connected 2 \n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # start from in_features and move to h1 , fc(fully connected)\n",
    "        self.fc2 = nn.Linear(h1,h2)             # start from h1 and move to h2 \n",
    "        self.out = nn.Linear(h2,out_features)   # start from h2 and move to out_features \n",
    "        \n",
    "                                                # Relu stands for rectified linear unit\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))                 # if output is less than 0 , then use 0 , else leave what it is. \n",
    "        x = F.relu(self.fc2(x))                 # if output is less than 0 , then use 0 , else leave what it is. \n",
    "        x = self.out(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward` function in your code implements **forward propagation** in the neural network. Here's a breakdown of how it works:\n",
    "1. Takes Input x:\n",
    "    * x represents the input data (e.g., 4 features of Iris flowers: sepal length, width, petal length, width).\n",
    "2. Passes Through Layers:\n",
    "    * Step 1: \n",
    "        * x = F.relu(self.fc1(x))\n",
    "        * Input x is passed through the first fully connected layer (fc1), then the ReLU activation function is applied.\n",
    "        * ReLU replaces negative values with 0 and keeps positive values unchanged.\n",
    "    * Step 2: \n",
    "        * x = F.relu(self.fc2(x))\n",
    "        * The output from fc1 is passed through the second fully connected layer (fc2), followed by another ReLU.\n",
    "    * Step 3: x = self.out(x)\n",
    "        * The final layer (out) produces raw scores (logits) for the 3 Iris flower classes without activation (no softmax here!).\n",
    "3. Returns Output:\n",
    "    * The raw scores (logits) for each class are returned. These will later be fed into a loss function (e.g., CrossEntropyLoss, which internally applies softmax). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a complete example with actual numbers to show how the calculations work in your Iris classifier:\n",
    "#### Example Input (1 Iris flower with 4 features):\n",
    "\n",
    "```py\n",
    " x = [5.1, 3.5, 1.4, 0.2]  # sepal_len, sepal_wid, petal_len, petal_wid\n",
    "```\n",
    "\n",
    "#### Layer 1 (fc1) Parameters:\n",
    "Let's assume these random weights and biases were initialized:\n",
    "\n",
    "**Weights (8×4 matrix):**\n",
    "\n",
    "```   W1 = [\n",
    "    [0.1, -0.2, 0.3, -0.4],  # Neuron 1 weights\n",
    "    [0.5, -0.1, 0.2, -0.3],  # Neuron 2 weights\n",
    "    [-0.2, 0.3, -0.1, 0.4],  # Neuron 3 weights\n",
    "    [0.4, -0.3, 0.2, -0.1],  # Neuron 4 weights\n",
    "    [0.2, 0.1, -0.3, 0.4],   # Neuron 5 weights\n",
    "    [-0.1, 0.4, -0.2, 0.3],  # Neuron 6 weights\n",
    "    [0.3, -0.4, 0.1, -0.2],  # Neuron 7 weights\n",
    "    [-0.3, 0.2, -0.4, 0.1]   # Neuron 8 weights\n",
    "]\n",
    "```\n",
    "**Bias (8×1 vector):**\n",
    "```py\n",
    "b1 = [0.1, -0.1, 0.2, -0.2, 0.3, -0.3, 0.4, -0.4]\n",
    "```\n",
    "\n",
    "### Calculation for fc1:\n",
    "#### 1. Matrix Multiplication (x × W1^T):\n",
    "```py\n",
    "# For first neuron:\n",
    "(5.1×0.1) + (3.5×-0.2) + (1.4×0.3) + (0.2×-0.4) = 0.51 - 0.7 + 0.42 - 0.08 = 0.15\n",
    "\n",
    "# Similarly for all 8 neurons:\n",
    "z1 = [0.15, 1.27, -0.38, 1.08, 0.82, -0.27, 0.53, -1.12]\n",
    "```\n",
    "\n",
    "#### 2. Add Bias\n",
    "```py\n",
    "z1 + b1 = [0.15+0.1, 1.27-0.1, -0.38+0.2, 1.08-0.2, 0.82+0.3, -0.27-0.3, 0.53+0.4, -1.12-0.4]\n",
    "        = [0.25, 1.17, -0.18, 0.88, 1.12, -0.57, 0.93, -1.52]\n",
    "```\n",
    "\n",
    "#### Apply ReLU:\n",
    "```py\n",
    "ReLU(z1 + b1) = [max(0,0.25), max(0,1.17), max(0,-0.18), \n",
    "                max(0,0.88), max(0,1.12), max(0,-0.57),\n",
    "                max(0,0.93), max(0,-1.52)]\n",
    "             = [0.25, 1.17, 0, 0.88, 1.12, 0, 0.93, 0]\n",
    "```\n",
    "\n",
    "#### Visualization:\n",
    "| Operation |\tNeuron 1    |   Neuron 2   |   Neuron 3  |    Neuron 4 |  Neuron 5    | Neuron 6   | Neuron 7  |  Neuron 8 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| W×x |   0.15    |  1.27   |  -0.38 |   1.08    |  0.82   |  -0.27 |   0.53    |  -1.12 |\n",
    "| + bias  |   0.25 | 1.17    |    -0.18  |    0.88 |  1.12    | -0.57  | 0.93 |   -1.52 |\n",
    "| ReLU    |   0.25   |   1.17  |    0    |  0.88   |  1.12  |   0    | 0.93   | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a manual seed for randomization \n",
    "torch.manual_seed(41)\n",
    "# Create instance of a model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
    "my_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/g7kffw4n1pv0rn40j1xbcchr0000gn/T/ipykernel_34216/2265344338.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  my_df['species'] = my_df['species'].replace('versicolor',2.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2      0.0\n",
       "1             4.9          3.0           1.4          0.2      0.0\n",
       "2             4.7          3.2           1.3          0.2      0.0\n",
       "3             4.6          3.1           1.5          0.2      0.0\n",
       "4             5.0          3.6           1.4          0.2      0.0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3      1.0\n",
       "146           6.3          2.5           5.0          1.9      1.0\n",
       "147           6.5          3.0           5.2          2.0      1.0\n",
       "148           6.2          3.4           5.4          2.3      1.0\n",
       "149           5.9          3.0           5.1          1.8      1.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['species'] = my_df['species'].replace('setosa',0.0)\n",
    "my_df['species'] = my_df['species'].replace('virginica',1.0)\n",
    "my_df['species'] = my_df['species'].replace('versicolor',2.0)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split! Set X,y\n",
    "X = my_df.drop('species',axis=1)\n",
    "y = my_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **X (Features):**\n",
    "    * Contains all columns except 'species' (sepal_length, sepal_width, petal_length, petal_width)\n",
    "    * These are the input measurements the model will use to make predictions.\n",
    "    * Shape: (150, 4) for 150 flowers with 4 features each.\n",
    "* **y (Target):**\n",
    "    * Contains only the 'species' column (converted to numbers: 0.0=setosa, 1.0=virginica, 2.0=versicolor)\n",
    "    * These are the correct answers the model will learn to predict.\n",
    "    * Shape: (150,) (a 1D array of labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these to numpy arrays \n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is typically followed by splitting X and y into training and test sets\n",
    "* Features (X) → The model learns patterns from these measurements.\n",
    "* Target (y) → The model tries to predict these labels correctly.\n",
    "* Train/Test Split (coming next) → Ensures you can evaluate the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y labels to tensor logs\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a neural network with multiple output values like [1.43, -0.4, 0.23], we often run the data through argmax to make the output easy to interpret, but because ArgMax has a terrible derivative, we cant use it with backpropagation. So, in ourder to train a neural network we use a softmax function, and the softmax output values are the predicted probabilities between 0 and 1.\n",
    "\n",
    "When the output is restricted between 0 and 1, we use CrossEntropy to determine how well the neural network fits the data. \n",
    "$$  CrossEntropy = -\\log(e^{\\text{softmax}}) $$ \n",
    "\n",
    "Now, to get the total error for the Neural Network, all we do is add up the **CrossEntropy** values. And, we can use Backpropagation to adjust the weights and biases and hopefully minimize the total error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the criterion of the model to measure the error\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Choose Adam optimzer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs) , lower our learning rate)\n",
    "optimizer = torch.optim.Adam(model.parameters() ,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 and loss : 1.1369255781173706\n",
      "Epoch : 10 and loss : 1.054518461227417\n",
      "Epoch : 20 and loss : 0.9172936081886292\n",
      "Epoch : 30 and loss : 0.6350035071372986\n",
      "Epoch : 40 and loss : 0.4044587016105652\n",
      "Epoch : 50 and loss : 0.2485925257205963\n",
      "Epoch : 60 and loss : 0.1463107168674469\n",
      "Epoch : 70 and loss : 0.09416623413562775\n",
      "Epoch : 80 and loss : 0.07249684631824493\n",
      "Epoch : 90 and loss : 0.06299241632223129\n"
     ]
    }
   ],
   "source": [
    "# train our model \n",
    "# epochs? (one run thru all the training data in our network)\n",
    "epoch = 100 \n",
    "losses = []\n",
    "for i in range(epoch):\n",
    "    # Go forward and get a prediction \n",
    "    y_pred = model.forward(X_train)     # Get predicted result\n",
    "    \n",
    "    # Measure a loss \n",
    "    loss = criterion(y_pred, y_train)   # predicted value vs the y_train\n",
    "    \n",
    "    # Keep track of losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "    \n",
    "    # Print every 10 epochs \n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch : {i} and loss : {loss}')\n",
    "    \n",
    "    # Do some backpropagation: take the error rate of forward propagation and feed it back thru the network to finetune the weights \n",
    "    optimizer.zero_grad()       # \"Reset error tracking before the next attempt\"\n",
    "    loss.backward()             # \"Trace error backward to see which weights caused it\"\n",
    "    optimizer.step()            # \"Update weights to reduce future errors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaulate model in test data\n",
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `with torch.no_grad():`\n",
    "    * Purpose: Temporarily turns off gradient tracking.\n",
    "    * Why?\n",
    "        * During evaluation, you don't need to calculate gradients (no weight updates).\n",
    "        * Saves memory and speeds up computation.\n",
    "    * Analogy: Like taking a test without a teacher grading your mistakes afterward.\n",
    "\n",
    "* `y_eval = model.forward(X_test)`\n",
    "    * What it does:\n",
    "        * Passes the test data (X_test) through the model to get predictions (y_eval).\n",
    "    * These are raw logits (unnormalized scores for each class).\n",
    "    * Example output for 3-class Iris:\n",
    "\n",
    "* `loss = criterion(y_eval, y_test)`\n",
    "    * What it does:\n",
    "        * Computes the loss (error) between predictions (y_eval) and true labels (y_test).\n",
    "    * Uses CrossEntropyLoss, which:\n",
    "        * Applies softmax to convert logits → probabilities.\n",
    "        * Compares probabilities to true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0404)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([-3.0885,  1.4384,  5.0835]) \t 2 \t 2\n",
      "2.) tensor([ 15.0765, -14.9693,   6.9545]) \t 0 \t 0\n",
      "3.) tensor([ 13.3655, -13.6654,   7.3508]) \t 0 \t 0\n",
      "4.) tensor([-3.3278,  1.4888,  5.6038]) \t 2 \t 2\n",
      "5.) tensor([-7.9918,  6.5556,  2.9374]) \t 1 \t 1\n",
      "6.) tensor([-8.8077,  6.8451,  4.3425]) \t 1 \t 1\n",
      "7.) tensor([ 12.6298, -13.0770,   7.4646]) \t 0 \t 0\n",
      "8.) tensor([ 13.7895, -13.9569,   7.1781]) \t 0 \t 0\n",
      "9.) tensor([-2.6056,  0.8098,  5.6859]) \t 2 \t 2\n",
      "10.) tensor([ 14.2774, -14.4782,   7.4792]) \t 0 \t 0\n",
      "11.) tensor([-3.5350,  1.5664,  5.9480]) \t 2 \t 2\n",
      "12.) tensor([-9.3633,  7.8234,  2.8512]) \t 1 \t 1\n",
      "13.) tensor([-0.6575, -0.9401,  5.6566]) \t 2 \t 2\n",
      "14.) tensor([ 0.0114, -1.7342,  6.3398]) \t 2 \t 2\n",
      "15.) tensor([-7.9024,  6.2620,  3.6053]) \t 1 \t 1\n",
      "16.) tensor([-9.3989,  8.0891,  2.1191]) \t 1 \t 1\n",
      "17.) tensor([-3.6551,  2.0553,  4.7556]) \t 2 \t 2\n",
      "18.) tensor([-6.7769,  5.1319,  3.9586]) \t 1 \t 1\n",
      "19.) tensor([-0.5989, -1.1255,  6.1067]) \t 2 \t 2\n",
      "20.) tensor([ 15.3395, -15.4729,   7.7586]) \t 0 \t 0\n",
      "21.) tensor([ 13.4389, -13.7408,   7.3890]) \t 0 \t 0\n",
      "22.) tensor([-10.5697,   8.9086,   2.8674]) \t 1 \t 1\n",
      "23.) tensor([-5.8915,  4.2872,  4.0974]) \t 1 \t 1\n",
      "24.) tensor([ 13.7074, -13.8552,   7.0895]) \t 0 \t 0\n",
      "25.) tensor([ 13.6157, -13.5960,   6.5884]) \t 0 \t 0\n",
      "26.) tensor([-0.7952, -0.9497,  6.1034]) \t 2 \t 2\n",
      "27.) tensor([ 15.6128, -15.7393,   7.8573]) \t 0 \t 0\n",
      "28.) tensor([-10.9798,   9.4469,   2.3429]) \t 1 \t 1\n",
      "29.) tensor([ 14.6739, -14.8323,   7.5374]) \t 0 \t 0\n",
      "30.) tensor([ 14.3411, -14.5121,   7.4267]) \t 0 \t 0\n",
      "We got 30 correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        \n",
    "        if y_test[i] == 0:\n",
    "            x = \"setosa\"\n",
    "        elif y_test[i] == 1:\n",
    "            x = \"virginica\"\n",
    "        else:\n",
    "            x = \"versicolor\"\n",
    "        \n",
    "        \n",
    "        # What type of flower class our network thinks it is \n",
    "        print(f'{i+1}.) {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}') \n",
    "\n",
    "        # Correct or not\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "\n",
    "print(f'We got {correct} correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that  `16.) tensor([-5.4799,  3.9468,  4.1003]) \t 1 \t 2` , is incorrect, if the `random_state=41`, but when `random_state=32`, it gives correct result and also the loss `tensor(0.0404)` is close to the minimum loss obtained while training `0.06299241632223129`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_iris = torch.tensor([4.7, 3.2, 1.3, 0.2])\n",
    "# Evaulate model in new data\n",
    "with torch.no_grad():\n",
    "    print(model(new_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whichever is the biggest number `13.8397`, is the species of the provided input data ie, setosa in our case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
