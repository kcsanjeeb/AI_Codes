{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in features: sepal length, sepal width, petal length, petal width\n",
    "* out features: Iris Setosa, Iris Versicolour, or Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/damiannolan/iris-neural-network/14a9df14a57ab9d350b7bc92b2903fa1f25c4f1c/img/iris_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Input Layer (4 features of flowers) --> HL1 (number of neurons) --> HL2(n) --> Ouput(3 Classes of Iris Flower)\n",
    "    # fc -- fully connected 1 , fully connected 2 \n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # start from in_features and move to h1 , fc(fully connected)\n",
    "        self.fc2 = nn.Linear(h1,h2)             # start from h1 and move to h2 \n",
    "        self.out = nn.Linear(h2,out_features)   # start from h2 and move to out_features \n",
    "        \n",
    "                                                # Relu stands for rectified linear unit\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))                 # if output is less than 0 , then use 0 , else leave what it is. \n",
    "        x = F.relu(self.fc2(x))                 # if output is less than 0 , then use 0 , else leave what it is. \n",
    "        x = self.out(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward` function in your code implements **forward propagation** in the neural network. Here's a breakdown of how it works:\n",
    "1. Takes Input x:\n",
    "    * x represents the input data (e.g., 4 features of Iris flowers: sepal length, width, petal length, width).\n",
    "2. Passes Through Layers:\n",
    "    * Step 1: \n",
    "        * x = F.relu(self.fc1(x))\n",
    "        * Input x is passed through the first fully connected layer (fc1), then the ReLU activation function is applied.\n",
    "        * ReLU replaces negative values with 0 and keeps positive values unchanged.\n",
    "    * Step 2: \n",
    "        * x = F.relu(self.fc2(x))\n",
    "        * The output from fc1 is passed through the second fully connected layer (fc2), followed by another ReLU.\n",
    "    * Step 3: x = self.out(x)\n",
    "        * The final layer (out) produces raw scores (logits) for the 3 Iris flower classes without activation (no softmax here!).\n",
    "3. Returns Output:\n",
    "    * The raw scores (logits) for each class are returned. These will later be fed into a loss function (e.g., CrossEntropyLoss, which internally applies softmax). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's a complete example with actual numbers to show how the calculations work in your Iris classifier:\n",
    "#### Example Input (1 Iris flower with 4 features):\n",
    "\n",
    "```py\n",
    " x = [5.1, 3.5, 1.4, 0.2]  # sepal_len, sepal_wid, petal_len, petal_wid\n",
    "```\n",
    "\n",
    "#### Layer 1 (fc1) Parameters:\n",
    "Let's assume these random weights and biases were initialized:\n",
    "\n",
    "**Weights (8×4 matrix):**\n",
    "```py\n",
    "    W1 = [\n",
    "    [0.1, -0.2, 0.3, -0.4],  # Neuron 1 weights\n",
    "    [0.5, -0.1, 0.2, -0.3],  # Neuron 2 weights\n",
    "    [-0.2, 0.3, -0.1, 0.4],  # Neuron 3 weights\n",
    "    [0.4, -0.3, 0.2, -0.1],  # Neuron 4 weights\n",
    "    [0.2, 0.1, -0.3, 0.4],   # Neuron 5 weights\n",
    "    [-0.1, 0.4, -0.2, 0.3],  # Neuron 6 weights\n",
    "    [0.3, -0.4, 0.1, -0.2],  # Neuron 7 weights\n",
    "    [-0.3, 0.2, -0.4, 0.1]   # Neuron 8 weights\n",
    "]\n",
    "```\n",
    "\n",
    "**Bias (8×1 vector):**\n",
    "```py\n",
    "b1 = [0.1, -0.1, 0.2, -0.2, 0.3, -0.3, 0.4, -0.4]\n",
    "```\n",
    "\n",
    "### Calculation for fc1:\n",
    "#### 1. Matrix Multiplication (x × W1^T):\n",
    "```py\n",
    "# For first neuron:\n",
    "(5.1×0.1) + (3.5×-0.2) + (1.4×0.3) + (0.2×-0.4) = 0.51 - 0.7 + 0.42 - 0.08 = 0.15\n",
    "\n",
    "# Similarly for all 8 neurons:\n",
    "z1 = [0.15, 1.27, -0.38, 1.08, 0.82, -0.27, 0.53, -1.12]\n",
    "```\n",
    "\n",
    "#### 2. Add Bias\n",
    "```py\n",
    "z1 + b1 = [0.15+0.1, 1.27-0.1, -0.38+0.2, 1.08-0.2, 0.82+0.3, -0.27-0.3, 0.53+0.4, -1.12-0.4]\n",
    "        = [0.25, 1.17, -0.18, 0.88, 1.12, -0.57, 0.93, -1.52]\n",
    "```\n",
    "\n",
    "#### Apply ReLU:\n",
    "```py\n",
    "ReLU(z1 + b1) = [max(0,0.25), max(0,1.17), max(0,-0.18), \n",
    "                max(0,0.88), max(0,1.12), max(0,-0.57),\n",
    "                max(0,0.93), max(0,-1.52)]\n",
    "             = [0.25, 1.17, 0, 0.88, 1.12, 0, 0.93, 0]\n",
    "```\n",
    "\n",
    "#### Visualization:\n",
    "| Operation |\tNeuron 1    |   Neuron 2   |   Neuron 3  |    Neuron 4 |  Neuron 5    | Neuron 6   | Neuron 7  |  Neuron 8 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| W×x |   0.15    |  1.27   |  -0.38 |   1.08    |  0.82   |  -0.27 |   0.53    |  -1.12 |\n",
    "| + bias  |   0.25 | 1.17    |    -0.18  |    0.88 |  1.12    | -0.57  | 0.93 |   -1.52 |\n",
    "| ReLU    |   0.25   |   1.17  |    0    |  0.88   |  1.12  |   0    | 0.93   | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a manual seed for randomization \n",
    "torch.manual_seed(41)\n",
    "# Create instance of a model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
    "my_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/g7kffw4n1pv0rn40j1xbcchr0000gn/T/ipykernel_59908/2265344338.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  my_df['species'] = my_df['species'].replace('versicolor',2.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2      0.0\n",
       "1             4.9          3.0           1.4          0.2      0.0\n",
       "2             4.7          3.2           1.3          0.2      0.0\n",
       "3             4.6          3.1           1.5          0.2      0.0\n",
       "4             5.0          3.6           1.4          0.2      0.0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3      1.0\n",
       "146           6.3          2.5           5.0          1.9      1.0\n",
       "147           6.5          3.0           5.2          2.0      1.0\n",
       "148           6.2          3.4           5.4          2.3      1.0\n",
       "149           5.9          3.0           5.1          1.8      1.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['species'] = my_df['species'].replace('setosa',0.0)\n",
    "my_df['species'] = my_df['species'].replace('virginica',1.0)\n",
    "my_df['species'] = my_df['species'].replace('versicolor',2.0)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split! Set X,y\n",
    "X = my_df.drop('species',axis=1)\n",
    "y = my_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these to numpy arrays \n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y labels to tensor logs\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the criterion of the model to measure the error\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Choose Adam optimzer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs) , lower our learning rate)\n",
    "optimizer = torch.optim.Adam(model.parameters() ,lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 and loss : 1.1397020816802979\n",
      "Epoch : 10 and loss : 1.0544098615646362\n",
      "Epoch : 20 and loss : 0.9166715741157532\n",
      "Epoch : 30 and loss : 0.6260551810264587\n",
      "Epoch : 40 and loss : 0.39875510334968567\n",
      "Epoch : 50 and loss : 0.24901509284973145\n",
      "Epoch : 60 and loss : 0.13584764301776886\n",
      "Epoch : 70 and loss : 0.07556889206171036\n",
      "Epoch : 80 and loss : 0.05038198083639145\n",
      "Epoch : 90 and loss : 0.03888977691531181\n"
     ]
    }
   ],
   "source": [
    "# train our model \n",
    "# epochs? (one run thru all the training data in our network)\n",
    "epoch = 100 \n",
    "losses = []\n",
    "for i in range(epoch):\n",
    "    # Go forward and get a prediction \n",
    "    y_pred = model.forward(X_train)     # Get predicted result\n",
    "    \n",
    "    # Measure a loss \n",
    "    loss = criterion(y_pred, y_train)   # predicted value vs the y_train\n",
    "    \n",
    "    # Keep track of losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "    \n",
    "    # Print every 10 epochs \n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch : {i} and loss : {loss}')\n",
    "    \n",
    "    # Do some backpropagation: take the error rate of forward propagation and feed it back thru the network to finetune the weights \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaulate model in test data\n",
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1286)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([-6.9816,  5.7408,  2.8455]) \t 1 \t 1\n",
      "2.) tensor([-10.1079,   9.1258,   1.3065]) \t 1 \t 1\n",
      "3.) tensor([-10.9584,   9.6312,   2.1591]) \t 1 \t 1\n",
      "4.) tensor([-2.8685,  1.0380,  5.6331]) \t 2 \t 2\n",
      "5.) tensor([-8.7846,  7.4753,  2.6232]) \t 1 \t 1\n",
      "6.) tensor([-0.5798, -1.5149,  7.0015]) \t 2 \t 2\n",
      "7.) tensor([-6.4517,  4.9981,  3.6210]) \t 1 \t 1\n",
      "8.) tensor([-2.5549,  0.6965,  5.7920]) \t 2 \t 2\n",
      "9.) tensor([-7.5313,  6.1537,  3.1311]) \t 1 \t 1\n",
      "10.) tensor([-10.7096,   9.6681,   1.3449]) \t 1 \t 1\n",
      "11.) tensor([-5.9053,  4.4576,  3.7346]) \t 1 \t 1\n",
      "12.) tensor([ 13.1833, -14.0755,   5.5305]) \t 0 \t 0\n",
      "13.) tensor([ 12.0059, -12.7652,   4.9037]) \t 0 \t 0\n",
      "14.) tensor([ 1.2265, -3.0406,  6.3975]) \t 2 \t 2\n",
      "15.) tensor([ 11.4834, -12.5821,   5.9413]) \t 0 \t 0\n",
      "16.) tensor([-5.4799,  3.9468,  4.1003]) \t 1 \t 2\n",
      "17.) tensor([ 11.9423, -12.8441,   5.3712]) \t 0 \t 0\n",
      "18.) tensor([-6.5523,  5.2595,  3.1084]) \t 2 \t 1\n",
      "19.) tensor([ 12.6839, -13.5421,   5.3429]) \t 0 \t 0\n",
      "20.) tensor([ 10.5711, -11.5527,   5.4033]) \t 0 \t 0\n",
      "21.) tensor([ 0.4430, -2.3670,  6.6304]) \t 2 \t 2\n",
      "22.) tensor([-9.8637,  8.6577,  2.0489]) \t 1 \t 1\n",
      "23.) tensor([ 11.6450, -12.7026,   5.8262]) \t 0 \t 0\n",
      "24.) tensor([ 12.7953, -13.5874,   5.1347]) \t 0 \t 0\n",
      "25.) tensor([ 0.8533, -2.8426,  6.8867]) \t 2 \t 2\n",
      "26.) tensor([-0.8277, -1.2091,  6.7632]) \t 2 \t 2\n",
      "27.) tensor([-3.2131,  1.3456,  5.6632]) \t 2 \t 2\n",
      "28.) tensor([ 3.5910e-03, -1.9779e+00,  6.7345e+00]) \t 2 \t 2\n",
      "29.) tensor([ 13.1331, -14.0004,   5.4373]) \t 0 \t 0\n",
      "30.) tensor([-3.4921,  1.7504,  5.2126]) \t 2 \t 2\n",
      "We got 28 correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        \n",
    "        if y_test[i] == 0:\n",
    "            x = \"setosa\"\n",
    "        elif y_test[i] == 1:\n",
    "            x = \"virginica\"\n",
    "        else:\n",
    "            x = \"versicolor\"\n",
    "        \n",
    "        \n",
    "        # What type of flower class our network thinks it is \n",
    "        print(f'{i+1}.) {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}') \n",
    "\n",
    "        # Correct or not\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "\n",
    "print(f'We got {correct} correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_iris = torch.tensor([4.7, 3.2, 1.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 12.7953, -13.5874,   5.1347])\n"
     ]
    }
   ],
   "source": [
    "# Evaulate model in new data\n",
    "with torch.no_grad():\n",
    "    print(model(new_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
